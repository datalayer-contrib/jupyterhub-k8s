#!/bin/sh
# Use https://www.shellcheck.net/ to reduce mistakes if you make changes to this file.

setup_helm () {
    echo "setup helm ${HELM_VERSION}"
    curl -sf https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | DESIRED_VERSION=${HELM_VERSION} bash
}

await_pebble() {
    kubectl rollout status --watch --timeout 300s deployment/pebble \
        && kubectl rollout status --watch --timeout 300s deployment/pebble-coredns \
        || {
        echo "Startup of Pebble failed!"
        kubectl describe pod -l app.kubernetes.io/name=pebble
        kubectl logs deploy/pebble --all-containers # --prefix
        kubectl describe pod -l app.kubernetes.io/name=pebble-coredns
        kubectl logs deploy/pebble-coredns --all-containers # --prefix
        exit 1
    }
}

await_jupyterhub() {
    kubectl rollout status --watch --timeout 300s deployment/proxy \
        && kubectl rollout status --watch --timeout 300s deployment/hub \
        && (
        if kubectl get deploy/autohttps &> /dev/null; then
            kubectl rollout status --watch --timeout 300s deployment/autohttps || exit 1
        fi
    )\
        || {
        echo "Startup of JupyterHub failed!"
        kubectl get all
        kubectl describe pod -l component=hub
        kubectl logs deploy/hub --all-containers # --prefix
        kubectl describe pod -l component=proxy
        kubectl logs deploy/proxy --all-containers # --prefix
        kubectl describe pod -l component=autohttps || true
        kubectl logs deploy/autohttps --all-containers || true # --prefix || true
        exit 1
    }
}

await_autohttps_tls_cert_acquisition() {
    i=0; while [ $i -ne 60 ]; do
        kubectl logs deploy/autohttps -c traefik | grep "Adding certificate" \
            && acquired_cert=true && break \
            || acquired_cert=false && sleep 0.5 && i=$((i + 1))
    done
    if [ "$acquired_cert" != "true" ]; then
        echo "Certificate acquisition failed!"
        kubectl get service,networkpolicy,configmap,pod
        kubectl describe pod -l app.kubernetes.io/name=pebble
        kubectl logs deploy/pebble --all-containers # --prefix
        kubectl describe pod -l app.kubernetes.io/name=pebble-coredns
        kubectl logs deploy/pebble-coredns --all-containers # --prefix
        kubectl describe pod -l component=autohttps
        kubectl logs deploy/autohttps --all-containers # --prefix
        exit 1
    fi
    # a precausion as pebble logs is a bad indicator of the readiness state of
    # Traefik's readiness to use the cert for TLS termination.
    sleep 1
}

await_autohttps_tls_cert_save() {
    i=0; while [ $i -ne 60 ]; do
        kubectl logs deploy/autohttps -c secret-sync | grep "Created secret" \
            && saved_cert=true && break \
            || saved_cert=false && sleep 0.5 && i=$((i + 1))
    done
    if [ "$saved_cert" != "true" ]; then
        echo "Certificate acquisition failed!"
        kubectl get service,networkpolicy,configmap,pod
        kubectl describe pod -l app.kubernetes.io/name=pebble
        kubectl logs deploy/pebble --all-containers # --prefix
        kubectl describe pod -l app.kubernetes.io/name=pebble-coredns
        kubectl logs deploy/pebble-coredns --all-containers # --prefix
        kubectl describe pod -l component=autohttps
        kubectl logs deploy/autohttps --all-containers # --prefix
        exit 1
    fi
}

setup_kubeval () {
    echo "setup kubeval ${KUBEVAL_VERSION}"
    curl -sfL https://github.com/instrumenta/kubeval/releases/download/${KUBEVAL_VERSION}/kubeval-linux-amd64.tar.gz | tar xz kubeval
    sudo mv kubeval /usr/local/bin/
}

full_namespace_report () {
    # Purpose:
    # - To chart agnostically print relevant information of the resources in a
    #   namespace.
    #
    # Arguments:
    # - Accepts a sequence of arguments such as "deploy/hub" "deploy/proxy". It
    #   will do `kubectl logs --all-containers <arg>` on them.
    #
    # Relevant references:
    # - ContainerStatus ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#containerstatus-v1-core

    # printf formatting: a bold bold colored topic with a divider.
    yellow=33
    red=31
    divider='--------------------------------------------------------------------------------'
    # GitHub Workflows resets formatting after \n, so its reapplied.
    export format="\n\033[${yellow};1m%s\n\033[${yellow};1m${divider}\033[0m\n"
    export format_error="\n\033[${red};1m%s\n\033[${red};1m${divider}\033[0m\n"

    printf "$format" "# Full namespace report"
    printf "$format" "## Resource overview"
    # list workloads (deployment,statefulset,daemonset,pod)
    printf "$format" "### \$ kubectl get deploy,sts,ds,pod"
    kubectl get deploy,sts,ds,pod
    # list config (secret,configmap)
    printf "$format" "### \$ kubectl get secret,cm"
    kubectl get secret,cm
    # list networking (service,ingress,networkpolicy)
    printf "$format" "### \$ kubectl get svc,ing,netpol"
    kubectl get svc,ing,netpol
    # list rbac (serviceaccount,role,rolebinding)
    printf "$format" "### \$ kubectl get sa,role,rolebinding"
    kubectl get sa,role,rolebinding

    # Check if any container of any pod has a non ready status
    PODS_WITH_NON_READY_CONTAINER=$(
        kubectl get pods -o json \
            | jq -r '
                .items[]
                | select(
                    any(.status.initContainerStatuses[]?; .ready == false)
                    or
                    any(.status.containerStatuses[]?; .ready == false)
                )
                | .metadata.name
        '
    )
    if [ -n "$PODS_WITH_NON_READY_CONTAINER" ]; then
        printf "$format_error" "## Pods with non-ready container(s) detected!"
        echo "$PODS_WITH_NON_READY_CONTAINER" | xargs --max-args=1 echo -

        for var in $PODS_WITH_NON_READY_CONTAINER; do
            printf "$format_error" "### \$ kubectl describe pod/$var"
            kubectl describe pod/$var
            printf "$format_error" "### \$ kubectl logs --all-containers pod/$var"
            kubectl logs --all-containers pod/$var || echo  # a newline on failure for consistency with non-failure
        done

    fi

    # Check if any container of any pod has a restartCount > 0. Then, we inspect
    # their logs with --previous. We also add --follow and --ignore-errors in
    # order to ensure we get the information from all containers, and combined
    # with --previous it will exit and not get stuck.
    #
    # ref: https://github.com/kubernetes/kubernetes/issues/97530
    PODS_WITH_RESTARTED_CONTAINERS=$(
        kubectl get pods -o json \
            | jq -r '
                .items[]
                | select(
                    any(.status.initContainerStatuses[]?; .restartCount > 0)
                    or
                    any(.status.containerStatuses[]?; .restartCount > 0)
                )
                | .metadata.name
        '
    )
    if [ -n "$PODS_WITH_RESTARTED_CONTAINERS" ]; then
        printf "$format_error" "## Pods with restarted containers detected!"
        echo "$PODS_WITH_RESTARTED_CONTAINERS" | xargs --max-args=1 echo -

        for var in $PODS_WITH_RESTARTED_CONTAINERS; do
            printf "$format_error" "### \$ kubectl describe pod/$var"
            kubectl describe pod/$var
            printf "$format_error" "### \$ kubectl logs --previous --all-containers --follow --ignore-errors pod/$var"
            kubectl logs --previous --all-containers --follow --ignore-errors pod/$var
        done
    fi

    # if any pods that should be scheduled by the user-scheduler are pending ->
    # show user-scheduler's logs
    PENDING_USER_PODS=$(
        kubectl get pods -l "component in (user-placeholder,singleuser-server)" -o json \
            | jq -r '
                .items[]
                | select(.status.phase == "Pending")
                | .metadata.name
        '
    )
    if [ -n "$PENDING_USER_PODS" ]; then
        printf "$format_error" "## Pending pods detected!"
        echo "$PENDING_USER_PODS" | xargs --max-args=1 echo -

        printf "$format_error" "### \$ kubectl logs --all-containers deploy/user-scheduler"
        kubectl logs --all-containers deploy/user-scheduler || echo  # a newline on failure for consistency with non-failure
    fi

    # show container logs of all important workloads passed to the function,
    # "deploy/hub" and "deploy/proxy" for example.
    if [ "$#" -gt 0 ]; then
        printf "$format" "## Important workload's logs"
        echo "$@" | xargs --max-args=1 echo -

        for var in "$@"; do
            printf "$format" "### \$ kubectl logs --all-containers $var"
            kubectl logs --all-containers $var || echo  # a newline on failure for consistency with non-failure
        done
    fi
}

install_and_run_chartpress_and_pebble () {
    helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
    helm repo update
    # Install a local ACME server
    helm install pebble jupyterhub/pebble --values dev-config-pebble.yaml
    # Build our images if needed and update values.yaml with the tags
    pip3 install --no-cache-dir -r dev-requirements.txt
    chartpress
    await_pebble  # jupyterhub's autohttps communicates with it as the ACME server
}
